# SegmentazioneNoduliCerebrali con Mask R-CNN ‚Äì BRISC2025

# üß† Tumor Segmentation with Mask R-CNN ‚Äì BRISC2025

## üîç Descrizione del progetto
Questo repository contiene un progetto per la segmentazione automatica di tumori cerebrali su immagini MRI, utilizzando un modello Mask R-CNN con backbone ResNet-50 + FPN implementato tramite la libreria Detectron2.

Il sistema √® stato addestrato e testato sul dataset pubblico **_BRISC2025_**, convertito in formato COCO con segmentazioni pixel-wise codificate tramite **Run-Length Encoding (RLE)**.

## üöÄ Contenuto del repository
- **üìÅ `BRISC2025/`**  - Dataset convertito in formato COCO + RLE
  - **üìÅ `classification_task/`**
    - üìÑ cartelle e file relativi a classificazione (non utlizzata in questo progetto)
  - **üìÅ `segmentation_task/`**
    - **üìÅ `test/`**
      - **üìÅ `images/`**
      - üìÑ `annotation.coco.json` ‚Äì File di annotazione in formato COCO.  
    - **üìÅ `train/`**
      - üìÑ `annotation.coco.json` ‚Äì File di annotazione in formato COCO.
    - üêç `generateAnnotationsCoco.py` ‚Äì Script per convertire immagini, categorie e maschere PNG in formato COCO.  
    - üêç `visualizzaMaschereRLE.py` ‚Äì Script per visualizzare immagini random con maschera ricostruita dalle annotazioni COCO per validare la conversione generata. 
      
   
  - üîó Dataset originale disponibile su [Kaggle ‚Äì BRISC2025](https://www.kaggle.com/datasets/briscdataset/brisc2025).

- **üìÅ `model/`**  
  - Modello Mask R-CNN addestrato (`model_final.pth`).  
  - Configurazioni e parametri associati.

- **üìÅ `report/`**  
  - üìÑ `documentazioneSistemiMultimediali.pdf` ‚Äì Documentazione completa del progetto.  
  - üìä `report_inferenza_testset.ods` ‚Äì Report completo sull‚Äôinferenza sul test set, con risultati immagine per immagine e metriche aggregate.

- **üìÅ `scripts/`**  
  - üêç Script per inferenza (`inferenzia.py`).  
  - üêç Script per valutazione e generazione di report (`valutazione.py`).  
  - Altri script ausiliari per la gestione dati.

- **üìÅ `colab/`**  
  - üìì `tumor_segmentation_colab.ipynb` ‚Äì Notebook eseguito su Google Colab contenente l‚Äôintero workflow del progetto:  
    - Setup ambiente  
    - Preprocessing e conversione dataset  
    - Training del modello  
    - Inferenza e analisi dei risultati  
    - Salvataggio modello e report

- **üìÅ `detectron2/`**  
  - Versione della libreria Detectron2 utilizzata, oppure il file `requirements.txt` con tutti i pacchetti necessari.  
  - Link ufficiale Detectron2: [https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2)

## üì¶ Struttura delle cartelle
‚îú‚îÄ‚îÄ dataset/
‚îÇ ‚îú‚îÄ‚îÄ annotations_coco.json
‚îÇ ‚îú‚îÄ‚îÄ convert_to_coco.py
‚îÇ ‚îú‚îÄ‚îÄ visualize_annotation.py
‚îÇ ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ model/
‚îÇ ‚îî‚îÄ‚îÄ model_final.pth
‚îú‚îÄ‚îÄ report/
‚îÇ ‚îú‚îÄ‚îÄ documentazioneSistemiMultimediali.pdf
‚îÇ ‚îî‚îÄ‚îÄ report_inferenza_testset.ods
‚îú‚îÄ‚îÄ scripts/
‚îÇ ‚îú‚îÄ‚îÄ inferenza.py
‚îÇ ‚îú‚îÄ‚îÄ valutazione.py
‚îÇ ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ colab/
‚îÇ ‚îî‚îÄ‚îÄ tumor_segmentation_colab.ipynb
‚îú‚îÄ‚îÄ detectron2/ (oppure requirements.txt)
‚îî‚îÄ‚îÄ README.md

## üõ†Ô∏è Requisiti
- Python 3.9+  
- Detectron2  
- OpenCV  
- NumPy  
- COCO API  
- matplotlib  

## üìë Dataset
- Dataset originale: [BRISC2025 su Kaggle](https://www.kaggle.com/datasets/briscdataset/brisc2025)  
- Conversione in formato COCO + RLE disponibile nella cartella `/dataset/` con script dedicato.

## üìà Risultati
- **IoU media:** 0.8189  
- **Dice coefficient:** 0.8857  
- **Specificity:** >0.99  
- Report completo disponibile in `/report/`.

## ‚úçÔ∏è Documentazione
Il report completo del progetto √® disponibile nella cartella `/report/`, e include:  
- Metodo  
- Pipeline dati  
- Dettaglio architettura  
- Risultati e analisi  
- Discussione critica e proposte future  

## üöÄ Getting Started
Per riprodurre il progetto:  
1. Clonare il repository.  
2. Installare i requisiti (`pip install -r requirements.txt` oppure configurare tramite il notebook Colab).  
3. Eseguire gli script di conversione e visualizzazione presenti in `/dataset/` per verificare la correttezza delle annotazioni.  
4. Avviare il training tramite il notebook in `/colab/` oppure tramite gli script Python in `/scripts/`.  
5. Eseguire inferenza e valutazione utilizzando il modello salvato in `/model/`.
