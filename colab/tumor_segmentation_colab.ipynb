{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER CLONARE REPO GITHUB CON GIT LFS ###\n",
        "\n",
        "import os\n",
        "\n",
        "# Configura percorso\n",
        "base_path = '/content/Progetti_IA'\n",
        "repo_name = 'SegmentazioneNoduliCerebrali'\n",
        "repo_url = 'https://github.com/s-villanova/SegmentazioneNoduliCerebrali.git'\n",
        "\n",
        "# Crea la cartella base se non esiste\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "repo_path = os.path.join(base_path, repo_name)\n",
        "\n",
        "# Installa Git LFS\n",
        "!apt-get install git-lfs -y\n",
        "!git lfs install\n",
        "\n",
        "if os.path.exists(repo_path):\n",
        "    print(f\"üìÇ La cartella '{repo_name}' esiste gi√†. Eseguo git pull...\")\n",
        "    %cd {repo_path}\n",
        "    !git stash --include-untracked --quiet\n",
        "    !git pull\n",
        "    !git lfs pull\n",
        "else:\n",
        "    print(f\"‚¨áÔ∏è Clono il repository '{repo_name}'...\")\n",
        "    %cd {base_path}\n",
        "    !git clone {repo_url}\n",
        "    %cd {repo_name}\n",
        "    !git lfs pull\n",
        "\n",
        "print(\"‚úÖ Repository pronto!\")"
      ],
      "metadata": {
        "id": "vXXc1m50U9KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER SALVARE BACKUP MODELLO E DATASET SU DRIVE ###\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r /content/SegmentazioneNoduliCerebrali /content/drive/MyDrive/Backup_SegmentazioneNoduliCerebrali/\n"
      ],
      "metadata": {
        "id": "m-yfd6rcE-CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER INSTALLARE DETECTRON PYTORCH E TORCHVISION ###\n",
        "\n",
        "# PyTorch + torchvision compatibili col runtime CUDA\n",
        "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "# PyTorch + torchvision compatibili col runtime CPU\n",
        "#!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
        "%cd /content/drive/MyDrive/Progetti_IA/SegmentazioneNoduliCerebrali/\n",
        "# 2. Installa dipendenze di compilazione\n",
        "!pip install pyyaml==6.0 cython 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "%cd detectron2\n",
        "!pip install -e .\n",
        "\n"
      ],
      "metadata": {
        "id": "WHNjQvsPdAqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER ESTRAZIONE DI EVENTUALI FILE ZIP ###\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Percorso al file ZIP su Drive\n",
        "zip_path = '/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/test/images.zip'\n",
        "\n",
        "# Cartella di destinazione\n",
        "extract_path = '/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/test/images/'\n",
        "\n",
        "# Crea la cartella se non esiste\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Estrazione\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"File scompattato correttamente in:\", extract_path)\n"
      ],
      "metadata": {
        "id": "9twpLRLaQv2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER IMPORTARE ISTANZE COCO ###\n",
        "\n",
        "\n",
        "# 1) Importa\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "# 2) Registra le partizioni\n",
        "register_coco_instances(\n",
        "    \"brain_train\",       # nome del dataset in Detectron2\n",
        "    {},                  # metadati (lascia vuoto se non ne hai di custom)\n",
        "    \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/train/annotation.coco.json\",\n",
        "    \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/train/images\"\n",
        ")\n",
        "\n",
        "register_coco_instances(\n",
        "    \"brain_test\",\n",
        "    {},\n",
        "    \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/test/annotation.coco.json\",\n",
        "    \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/test/images\"\n",
        ")\n",
        "\n",
        "# 3) Verifica\n",
        "for split in [\"brain_train\", \"brain_test\"]:\n",
        "    data = DatasetCatalog.get(split)\n",
        "    meta = MetadataCatalog.get(split)\n",
        "    print(f\"{split}: {len(data)} immagini, categorie = {meta.thing_classes if hasattr(meta, 'thing_classes') else 'non definito'}\")\n"
      ],
      "metadata": {
        "id": "UeFUaPhVkS-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER TRAINING MODELLO ###\n",
        "\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultTrainer, HookBase\n",
        "from detectron2.data import build_detection_train_loader, detection_utils as utils\n",
        "from detectron2.data import transforms as T\n",
        "from detectron2.modeling import GeneralizedRCNN, META_ARCH_REGISTRY\n",
        "\n",
        "# --- 1) Dice loss ---\n",
        "def dice_loss(pred_mask, target_mask, smooth=1e-6):\n",
        "    pred_mask = pred_mask.sigmoid()\n",
        "    inter = (pred_mask * target_mask).sum(dim=[1,2])\n",
        "    union = pred_mask.sum(dim=[1,2]) + target_mask.sum(dim=[1,2])\n",
        "    return (1 - (2*inter+smooth)/(union+smooth)).mean()\n",
        "\n",
        "# --- 2) Hook per aggiungere il Dice loss dopo la mask_loss standard ---\n",
        "class DiceLossHook(HookBase):\n",
        "    def after_step(self):\n",
        "        \"\"\"\n",
        "        Viene chiamato *dopo* che trainer.model.losses √® stato calcolato.\n",
        "        Qui recuperiamo:\n",
        "          - il dizionario self.trainer.storage.latest(), contenente 'loss_mask'\n",
        "          - i tensor self.trainer.model.roi_heads._last_mask_logits e _last_gt_masks\n",
        "        e sommiamo il dice loss.\n",
        "        \"\"\"\n",
        "        metrics = self.trainer.storage._latest  # dict di losses correnti\n",
        "        # recupera i logits e le gt masks salvati in training\n",
        "        mh = self.trainer.model.roi_heads\n",
        "        if hasattr(mh, \"_last_mask_logits\") and hasattr(mh, \"_last_gt_masks\"):\n",
        "            logits = mh._last_mask_logits\n",
        "            gt_masks = mh._last_gt_masks\n",
        "            if logits is not None and gt_masks is not None:\n",
        "                d = dice_loss(logits, gt_masks)\n",
        "                # somma in-place\n",
        "                metrics[\"loss_mask\"] += d.item()\n",
        "                # e segnala al backprop\n",
        "                self.trainer.storage._latest[\"loss_mask\"] = metrics[\"loss_mask\"]\n",
        "                # aggiungi il dice al dict per il backward\n",
        "                self.trainer.storage._latest[\"d2_dice_loss\"] = d.item()\n",
        "                # infine, aggiungi al grad\n",
        "                self.trainer.model._losses[\"loss_mask\"] = (\n",
        "                    self.trainer.model._losses[\"loss_mask\"] + d\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "# Ambient and warning setup\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/Progetti_IA/SegmentazioneNoduliCerebrali/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.META_ARCHITECTURE = \"GeneralizedRCNN\"\n",
        "cfg.MODEL.MASK_ON = True\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"brain_train\",)\n",
        "cfg.DATASETS.TEST = (\"brain_test\",)\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 14\n",
        "cfg.SOLVER.BASE_LR = 0.004\n",
        "cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
        "\n",
        "cfg.SOLVER.AMP.ENABLED = True\n",
        "cfg.MODEL.DEVICE = \"cuda\" # usa \"cpu\" se non hai GPU\n",
        "\n",
        "cfg.SOLVER.MAX_ITER = 8000\n",
        "cfg.SOLVER.GAMMA = 0.6\n",
        "cfg.SOLVER.STEPS = [3000, 6000]\n",
        "cfg.SOLVER.WARMUP_ITERS = 500\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
        "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
        "cfg.SOLVER.MOMENTUM = 0.9\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "cfg.TEST.EVAL_PERIOD = 1000\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 5\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (512,)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 512\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "# Output\n",
        "cfg.OUTPUT_DIR = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented\"\n",
        "#cfg.MODEL.WEIGHTS = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented/model_final.pth\"\n",
        "\n",
        "# === 3) Custom mapper per COCO RLE ===\n",
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)\n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "\n",
        "    # 1) Definisci le stesse augmentations\n",
        "    augmentation_list = [\n",
        "        T.Resize((512, 512)),\n",
        "        T.RandomFlip(prob=0.5),\n",
        "        T.RandomRotation(angle=[-15, 15]),\n",
        "        T.RandomCrop(crop_type=\"relative_range\", crop_size=[0.8, 0.8]),\n",
        "    ]\n",
        "\n",
        "    # 2) Applica le augmentations all‚Äôimmagine\n",
        "    aug_input = T.AugInput(image)\n",
        "    transforms = T.AugmentationList(augmentation_list)(aug_input)\n",
        "    image = aug_input.image\n",
        "    new_h, new_w = image.shape[:2]\n",
        "\n",
        "    # 3) **RICAMPIONA** le annotation con le stesse transforms!\n",
        "    annos = []\n",
        "    for ann in dataset_dict[\"annotations\"]:\n",
        "        ann_trans = utils.transform_instance_annotations(\n",
        "            ann, transforms, (new_h, new_w)\n",
        "        )\n",
        "        annos.append(ann_trans)\n",
        "\n",
        "    # 4) Crea finalmente le Instances ‚Äúallineate‚Äù\n",
        "    instances = utils.annotations_to_instances(\n",
        "        annos, (new_h, new_w), mask_format=\"bitmask\"\n",
        "    )\n",
        "\n",
        "    # 5) Ritorna tutto nel formato detectron2\n",
        "    dataset_dict[\"image\"]     = torch.as_tensor(image.transpose(2,0,1), dtype=torch.float32)\n",
        "    dataset_dict[\"instances\"] = instances\n",
        "    return dataset_dict\n",
        "\n",
        "# === 4) Trainer custom con mapper ===\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
        "\n",
        "# === 5) Training ===\n",
        "trainer = CustomTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "tLFwWeeFo2uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT DEBUG PER VALIDARE MAPER E AUGMENTATION USATI IN TRAINING ###\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from detectron2.data import DatasetCatalog, detection_utils as utils\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "dataset_dicts = DatasetCatalog.get(\"brain_train\")\n",
        "\n",
        "def debug_mapper(dataset_dict):\n",
        "    d = copy.deepcopy(dataset_dict)\n",
        "    img = utils.read_image(d[\"file_name\"], format=\"BGR\")  # uint8 0‚Äì255\n",
        "    h0, w0 = img.shape[:2]\n",
        "\n",
        "    aug_list = [\n",
        "        T.Resize((512, 512)),\n",
        "        T.RandomFlip(prob=0.5),\n",
        "        T.RandomRotation(angle=[-15, 15]),\n",
        "        T.RandomCrop(crop_type=\"relative_range\", crop_size=[0.8, 0.8]),\n",
        "    ]\n",
        "    aug_input = T.AugInput(img)\n",
        "    transforms = T.AugmentationList(aug_list)(aug_input)\n",
        "    img_trans = aug_input.image   # ancora uint8 0‚Äì255\n",
        "    h, w = img_trans.shape[:2]\n",
        "\n",
        "    annos = []\n",
        "    for ann in d[\"annotations\"]:\n",
        "        annos.append(utils.transform_instance_annotations(\n",
        "            ann, transforms, (h, w)\n",
        "        ))\n",
        "    instances = utils.annotations_to_instances(\n",
        "        annos, (h, w), mask_format=\"bitmask\"\n",
        "    )\n",
        "\n",
        "    # Restituisco l'immagine raw e le instances\n",
        "    return img_trans, instances\n",
        "\n",
        "# Visualizzo 4 campioni\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10,10))\n",
        "axes = axes.flatten()\n",
        "for ax in axes:\n",
        "    sample = random.choice(dataset_dicts)\n",
        "    img, inst = debug_mapper(sample)\n",
        "\n",
        "    # BGR -> RGB\n",
        "    img_rgb = img[:, :, ::-1]\n",
        "\n",
        "    ax.imshow(img_rgb)\n",
        "    # contorni delle maschere\n",
        "    masks = inst.gt_masks.tensor.cpu().numpy()  # [N,H,W]\n",
        "    for m in masks:\n",
        "        ax.contour(m, levels=[0.5], colors='r', linewidths=1)\n",
        "\n",
        "    ax.set_title(f\"Image ID {sample['image_id']}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "69Nf-1TdOcyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER EVALUATION CON COCO EVALUATOR ###\n",
        "\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# 1) Configurazione come prima\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/Progetti_IA/SegmentazioneNoduliCerebrali/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TEST = (\"brain_test\",)\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "cfg.MODEL.WEIGHTS = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented/model_0007999.pth\"\n",
        "cfg.OUTPUT_DIR = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented_eval\"\n",
        "\n",
        "cfg.MODEL.DEVICE = \"cuda\" # usa \"cpu\" se non hai GPU\n",
        "\n",
        "# 2) DefaultPredictor costruisce internamente il modello e il preprocess\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# 3) COCOEvaluator sullo split brain_test\n",
        "evaluator = COCOEvaluator(\"brain_test\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "\n",
        "# 4) DataLoader di test\n",
        "test_loader = build_detection_test_loader(cfg, \"brain_test\")\n",
        "\n",
        "# 5) Inference + metriche\n",
        "res = inference_on_dataset(predictor.model, test_loader, evaluator)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "luYeOpNf5eGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER VISUALIZZARE EVENTI TENSORBOARD ###\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented/\n"
      ],
      "metadata": {
        "id": "WsbUhe0K824S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER ESEGUIRE INFERENZA CON IMMAGINE CARICATA DAL PROPRIO PC ###\n",
        "\n",
        "import cv2\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1) Configura il modello ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(\"/content/Progetti_IA/SegmentazioneNoduliCerebrali/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "cfg.DATASETS.TEST = (\"brain_test\",)\n",
        "cfg.DATASETS.TRAIN = (\"brain_train\",)\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.DEVICE = \"cuda\"  # usa \"cpu\" se non hai GPU\n",
        "\n",
        "cfg.MODEL.WEIGHTS = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented/model_0007999.pth\"\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2) Carica immagine ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"‚ñ∂Ô∏è Carica un‚Äôimmagine dal tuo PC:\")\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded.keys()))\n",
        "image = cv2.imread(file_name)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3) Inferenza ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "outputs = predictor(image)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4) Visualizza risultati ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "\n",
        "instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "v = Visualizer(image[:, :, ::-1], metadata=metadata, scale=1.2)\n",
        "out = v.draw_instance_predictions(instances)\n",
        "\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "37YH2a15d9tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT GRADIO PER TESTING MODELLO ###\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import torch\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, Metadata\n",
        "from detectron2.structures import Instances, BitMasks, Boxes\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from pycocotools import mask as maskUtils\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score,\n",
        "    jaccard_score, balanced_accuracy_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "import traceback\n",
        "\n",
        "from detectron2.utils.colormap import random_color\n",
        "\n",
        "\n",
        "\n",
        "def no_jitter_color(color, brightness_factor=1.0):\n",
        "    # Ignora qualsiasi modifica e restituisce sempre il colore originale\n",
        "    return color\n",
        "\n",
        "# Sovrascrivi la funzione privata _jitter_color usata da Visualizer\n",
        "Visualizer._jitter_color = staticmethod(no_jitter_color)\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\n",
        "    \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        ")\n",
        "cfg.DATASETS.TEST = (\"brain_test\",)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "cfg.MODEL.DEVICE = \"cpu\"\n",
        "cfg.MODEL.WEIGHTS = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented/model_0007999.pth\"\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "orig_metadata = MetadataCatalog.get(\"brain_test\")\n",
        "\n",
        "PRED_COLOR = (255, 255, 0)\n",
        "GT_COLOR   = (76, 145, 255)\n",
        "\n",
        "def fixed_random_color(class_index=0, *, rgb=False):\n",
        "    # Sempre lo stesso colore, per esempio GT_COLOR normalizzato a 0-1 se rgb=True\n",
        "    color = np.array(GT_COLOR, dtype=np.float32) / 255.0 if rgb else GT_COLOR\n",
        "    return tuple(color)\n",
        "\n",
        "# Patch\n",
        "import detectron2.utils.colormap as colormap_module\n",
        "colormap_module.random_color = fixed_random_color\n",
        "\n",
        "dataset_dicts = DatasetCatalog.get(\"brain_test\")\n",
        "immagini = [os.path.basename(d[\"file_name\"]) for d in dataset_dicts if d.get(\"annotations\")]\n",
        "NUM_CLASSES = cfg.MODEL.ROI_HEADS.NUM_CLASSES\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ UTILS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def segm_to_mask(segm, h, w):\n",
        "    if isinstance(segm, list):\n",
        "        rles = maskUtils.frPyObjects(segm, h, w)\n",
        "        rle  = maskUtils.merge(rles)\n",
        "    elif isinstance(segm, dict) and isinstance(segm.get(\"counts\"), list):\n",
        "        rle = maskUtils.frPyObjects(segm, h, w)\n",
        "    else:\n",
        "        rle = segm\n",
        "    return maskUtils.decode(rle).astype(np.uint8)\n",
        "\n",
        "def hausdorff(u, v):\n",
        "    u_pts = np.argwhere(u)\n",
        "    v_pts = np.argwhere(v)\n",
        "    if u_pts.size == 0 or v_pts.size == 0:\n",
        "        return 0.0\n",
        "    return max(\n",
        "        directed_hausdorff(u_pts, v_pts)[0],\n",
        "        directed_hausdorff(v_pts, u_pts)[0]\n",
        "    )\n",
        "\n",
        "def crea_overlay(gt_all, pred_all, canvas_size=512, max_crop=300):\n",
        "    gt_mask = gt_all.sum(axis=0) > 0\n",
        "    pr_mask = pred_all.sum(axis=0) > 0\n",
        "    both    = gt_mask & pr_mask\n",
        "    only_gt = gt_mask & ~pr_mask\n",
        "    only_pr = pr_mask & ~gt_mask\n",
        "\n",
        "    H, W = gt_mask.shape\n",
        "    overlay = np.ones((H, W, 3), dtype=np.uint8) * 240\n",
        "    overlay[only_gt] = GT_COLOR\n",
        "    overlay[only_pr] = PRED_COLOR\n",
        "    overlay[both]   = (28, 255, 28)\n",
        "\n",
        "\n",
        "\n",
        "    coords = np.argwhere(gt_mask | pr_mask)\n",
        "    if coords.size == 0:\n",
        "        return np.ones((canvas_size, canvas_size, 3), dtype=np.uint8) * 240\n",
        "    y0, x0 = coords.min(axis=0)\n",
        "    y1, x1 = coords.max(axis=0) + 1\n",
        "    crop = overlay[y0:y1, x0:x1]\n",
        "    crop = cv2.copyMakeBorder(crop, 1,1,1,1, cv2.BORDER_CONSTANT, value=(240,240,240))\n",
        "    h, w = crop.shape[:2]\n",
        "    scale = max_crop / max(h, w)\n",
        "    crop = cv2.resize(crop, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    canvas = np.ones((canvas_size, canvas_size, 3), dtype=np.uint8) * 240\n",
        "    ys = (canvas_size - crop.shape[0]) // 2\n",
        "    xs = (canvas_size - crop.shape[1]) // 2\n",
        "    canvas[ys:ys+crop.shape[0], xs:xs+crop.shape[1]] = crop\n",
        "    return canvas\n",
        "def build_gt_instances(gt_item, H, W):\n",
        "    masks = []\n",
        "    classes = []\n",
        "    boxes = []\n",
        "    for ann in gt_item.get(\"annotations\", []):\n",
        "        m = segm_to_mask(ann[\"segmentation\"], H, W).astype(bool)\n",
        "        masks.append(m)\n",
        "        classes.append(ann[\"category_id\"])\n",
        "        # Convert [x, y, w, h] to [x1, y1, x2, y2]\n",
        "        x, y, w, h = ann[\"bbox\"]\n",
        "        boxes.append([x, y, x + w, y + h])\n",
        "    inst = Instances((H, W))\n",
        "    inst.pred_masks = BitMasks(np.array(masks))\n",
        "    inst.pred_classes = np.array(classes)\n",
        "    inst.pred_boxes = Boxes(torch.tensor(boxes))\n",
        "    return inst\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MAIN FUNCTION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def visualizza_con_metriche(nome_file):\n",
        "    try:\n",
        "        img_path = os.path.join(\n",
        "            \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/BRISC2025/segmentation_task/test/images\",\n",
        "            nome_file\n",
        "        )\n",
        "        if not os.path.isfile(img_path):\n",
        "            return None, None, None, None, f\"‚ùå File non trovato: {img_path}\"\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = img[:, :, ::-1]\n",
        "        H, W = img.shape[:2]\n",
        "\n",
        "        out = predictor(img)\n",
        "        inst = out[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        gt_item = next((d for d in dataset_dicts if os.path.basename(d[\"file_name\"]) == nome_file), None)\n",
        "        if gt_item is None:\n",
        "            return img_rgb, None, None, None, \"‚ùå GT non trovata!\"\n",
        "\n",
        "        gt_all   = np.zeros((NUM_CLASSES, H, W), dtype=bool)\n",
        "        pred_all = np.zeros((NUM_CLASSES, H, W), dtype=bool)\n",
        "        for ann in gt_item.get(\"annotations\", []):\n",
        "            m = segm_to_mask(ann[\"segmentation\"], H, W).astype(bool)\n",
        "            gt_all[ann[\"category_id\"]] |= m\n",
        "        for i, m in enumerate(inst.pred_masks if inst.has(\"pred_masks\") else []):\n",
        "            cls = inst.pred_classes[i]\n",
        "            pred_all[cls] |= m.numpy()\n",
        "\n",
        "        report = \"\"\n",
        "        for cls in range(NUM_CLASSES):\n",
        "            yt = gt_all[cls].ravel(); yp = pred_all[cls].ravel()\n",
        "            if not (yt.any() or yp.any()): continue\n",
        "            iou  = jaccard_score(yt, yp, zero_division=0)\n",
        "            dice = f1_score(yt, yp, zero_division=0)\n",
        "            prec = precision_score(yt, yp, zero_division=0)\n",
        "            rec  = recall_score(yt, yp, zero_division=0)\n",
        "            tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0,1]).ravel()\n",
        "            spec   = tn / (tn + fp + 1e-6)\n",
        "            balacc = balanced_accuracy_score(yt, yp)\n",
        "            hd     = hausdorff(gt_all[cls], pred_all[cls])\n",
        "            report += (f\"Classe {cls}: IoU {iou:.3f}, DICE {dice:.3f}, Prec {prec:.3f}, \"\n",
        "                       f\"Rec {rec:.3f}, Spec {spec:.3f}, BalAcc {balacc:.3f}, \"\n",
        "                       f\"Hausdorff {hd:.1f}px\\n\")\n",
        "\n",
        "        meta_pred = Metadata()\n",
        "        meta_pred.thing_classes = orig_metadata.thing_classes\n",
        "        meta_pred.thing_colors  = [PRED_COLOR] * NUM_CLASSES\n",
        "        vp = Visualizer(img_rgb, meta_pred, scale=1.0, instance_mode=ColorMode.SEGMENTATION)\n",
        "        vp._default_mask_alpha = 1.0\n",
        "        vis_pred = vp.draw_instance_predictions(inst).get_image()\n",
        "\n",
        "        meta_gt = Metadata()\n",
        "        meta_gt.thing_classes = orig_metadata.thing_classes\n",
        "        meta_gt.thing_colors  = [GT_COLOR] * NUM_CLASSES\n",
        "        gt_inst = build_gt_instances(gt_item, H, W)\n",
        "        vg = Visualizer(img_rgb, meta_gt, scale=1.0, instance_mode=ColorMode.SEGMENTATION)\n",
        "        vg._default_mask_alpha = 1.0\n",
        "        vis_gt = vg.draw_instance_predictions(gt_inst).get_image()\n",
        "\n",
        "        overlay = crea_overlay(gt_all.astype(np.uint8), pred_all.astype(np.uint8))\n",
        "        return img_rgb, vis_pred, vis_gt, overlay, report\n",
        "    except Exception as e:\n",
        "        print(traceback.format_exc())\n",
        "        return None, None, None, None, f\"‚ùå Errore interno:\\n{e}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gr.Interface(\n",
        "        fn=visualizza_con_metriche,\n",
        "        inputs=gr.Dropdown(choices=immagini, label=\"Seleziona immagine\"),\n",
        "        outputs=[\n",
        "            gr.Image(label=\"Originale\"),\n",
        "            gr.Image(label=\"Predizione\"),\n",
        "            gr.Image(label=\"Ground Truth\"),\n",
        "            gr.Image(label=\"Overlay: Giallo=Predetto, Blu=GT, Verde=Comune\"),\n",
        "            gr.Textbox(label=\"Metriche\", lines=8)\n",
        "        ],\n",
        "        title=\"Segmentation QA con metriche su sfondo bianco\",\n",
        "        allow_flagging=\"never\"\n",
        "    ).launch(debug=True)\n"
      ],
      "metadata": {
        "id": "_SUEAkHvW9c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER INFERENZA E GENERAZIONE REPORT CSV ###\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from pycocotools import mask as maskUtils\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    jaccard_score,\n",
        "    balanced_accuracy_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIGURAZIONE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/Progetti_IA/SegmentazioneNoduliCerebrali/detectron2/configs/\"\n",
        "                    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TEST = (\"brain_test\",)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # soglia alta\n",
        "cfg.MODEL.DEVICE = \"cuda\" # usa \"cpu\" se non hai GPU\n",
        "cfg.MODEL.WEIGHTS = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/model/augmented/model_0007999.pth\"\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "metadata  = MetadataCatalog.get(\"brain_test\")\n",
        "dataset_dicts = DatasetCatalog.get(\"brain_test\")\n",
        "thing_classes = metadata.thing_classes\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ UTILITY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def segm_to_mask(segm, h, w):\n",
        "    \"\"\"Da COCO RLE/poligono a maschera binaria HxW.\"\"\"\n",
        "    if isinstance(segm, list):\n",
        "        rles = maskUtils.frPyObjects(segm, h, w)\n",
        "        rle  = maskUtils.merge(rles)\n",
        "    elif isinstance(segm.get(\"counts\"), list):\n",
        "        rle = maskUtils.frPyObjects(segm, h, w)\n",
        "    else:\n",
        "        rle = segm\n",
        "    return maskUtils.decode(rle).astype(np.uint8)\n",
        "\n",
        "def hausdorff(u, v):\n",
        "    uc = np.argwhere(u)\n",
        "    vc = np.argwhere(v)\n",
        "    if len(uc)==0 or len(vc)==0:\n",
        "        return 0.0\n",
        "    return max(\n",
        "        directed_hausdorff(uc, vc)[0],\n",
        "        directed_hausdorff(vc, uc)[0]\n",
        "    )\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ COLLECT STATS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "rows = []\n",
        "# per classe GT: (correct, wrong)\n",
        "agg = {cls: {\"correct\":0, \"wrong\":0} for cls in thing_classes}\n",
        "\n",
        "n_found = 0\n",
        "n_not_found = 0\n",
        "\n",
        "for idx, item in enumerate(dataset_dicts, 1):\n",
        "    fname = os.path.basename(item[\"file_name\"])\n",
        "    img_bgr = cv2.imread(item[\"file_name\"])\n",
        "    h, w = img_bgr.shape[:2]\n",
        "\n",
        "    outputs = predictor(img_bgr)\n",
        "    inst = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    # trova la predizione con conf pi√π alta, se c'√®\n",
        "    if len(inst) == 0:\n",
        "        pred_cls = \"\"\n",
        "        pred_mask = np.zeros((h,w), np.uint8)\n",
        "        n_not_found += 1\n",
        "    else:\n",
        "        scores = inst.scores.numpy()\n",
        "        best = scores.argmax()\n",
        "        pred_cls = int(inst.pred_classes[best])\n",
        "        pred_mask = inst.pred_masks[best].numpy().astype(np.uint8)\n",
        "        n_found += 1\n",
        "\n",
        "    # ground-truth unico per immagine (assumiamo 1 sola annotazione per immagine)\n",
        "    gt_ann = item[\"annotations\"][0]\n",
        "    gt_cls = gt_ann[\"category_id\"]\n",
        "    gt_mask = segm_to_mask(gt_ann[\"segmentation\"], h, w)\n",
        "\n",
        "    # match classe?\n",
        "    match = 1 if (pred_cls == gt_cls) else 0\n",
        "    if pred_cls == \"\":\n",
        "        # nessuna predizione\n",
        "        metrics = dict(iou=0,dice=0,precision=0,recall=0,\n",
        "                       specificity=0,balanced_acc=0,hausdorff_px=0)\n",
        "    else:\n",
        "        # calcola metriche pixel-wise\n",
        "        yt = gt_mask.flatten()\n",
        "        yp = pred_mask.flatten()\n",
        "        iou    = jaccard_score(yt, yp, zero_division=0)\n",
        "        dice   = f1_score(yt, yp, zero_division=0)\n",
        "        prec   = precision_score(yt, yp, zero_division=0)\n",
        "        rec    = recall_score(yt, yp, zero_division=0)\n",
        "        balacc = balanced_accuracy_score(yt, yp)\n",
        "        tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0,1]).ravel()\n",
        "        spec   = tn / (tn + fp + 1e-6)\n",
        "        hd     = hausdorff(gt_mask>0, pred_mask>0)\n",
        "        metrics = dict(iou=iou, dice=dice, precision=prec,\n",
        "                       recall=rec, specificity=spec,\n",
        "                       balanced_acc=balacc, hausdorff_px=hd)\n",
        "\n",
        "    # aggiorna aggregati per classe GT\n",
        "    cls_name = thing_classes[gt_cls]\n",
        "    if pred_cls == gt_cls:\n",
        "        agg[cls_name][\"correct\"] += 1\n",
        "    else:\n",
        "        agg[cls_name][\"wrong\"]   += 1\n",
        "\n",
        "    rows.append([\n",
        "        fname,\n",
        "        cls_name,\n",
        "        thing_classes[pred_cls] if pred_cls!=\"\" else \"\",\n",
        "        match,\n",
        "        f\"{metrics['iou']:.4f}\",\n",
        "        f\"{metrics['dice']:.4f}\",\n",
        "        f\"{metrics['precision']:.4f}\",\n",
        "        f\"{metrics['recall']:.4f}\",\n",
        "        f\"{metrics['specificity']:.4f}\",\n",
        "        f\"{metrics['balanced_acc']:.4f}\",\n",
        "        f\"{metrics['hausdorff_px']:.2f}\",\n",
        "    ])\n",
        "\n",
        "    print(f\"[{idx}/{len(dataset_dicts)}] {fname} ‚Üí GT={cls_name}  PRED=\"\n",
        "          f\"{metrics['iou']:.3f}, match={match}\")\n",
        "\n",
        "# calcola global means su tumori trovati\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"image\",\"gt_class\",\"pred_class\",\"match\",\n",
        "    \"iou\",\"dice\",\"precision\",\"recall\",\n",
        "    \"specificity\",\"balanced_acc\",\"hausdorff_px\"\n",
        "])\n",
        "df.to_csv(\"/content/Progetti_IA/SegmentazioneNoduliCerebrali/report/metrics_per_image.csv\", index=False)\n",
        "\n",
        "# prepariamo gli aggregati per classe\n",
        "agg_rows = []\n",
        "for cls, v in agg.items():\n",
        "    agg_rows.append([cls, v[\"correct\"], v[\"wrong\"]])\n",
        "\n",
        "# medie globali (solo match o mismatch ma con predizione)\n",
        "found_df = df[df[\"pred_class\"]!=\"\"]\n",
        "global_means = found_df[[\"iou\",\"dice\",\"precision\",\"recall\",\n",
        "                        \"specificity\",\"balanced_acc\",\"hausdorff_px\"]].astype(float).mean()\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ SCRITTURA FINALE CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "with open(\"/content/Progetti_IA/SegmentazioneNoduliCerebrali/report/metrics_per_image.csv\", \"a\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "\n",
        "    # vuota\n",
        "    w.writerow([])\n",
        "    # Aggregati per classe\n",
        "    w.writerow([\"Aggregati per classe\"])\n",
        "    w.writerow([\"gt_class\",\"correct_preds\",\"wrong_preds\"])\n",
        "    w.writerows(agg_rows)\n",
        "\n",
        "    # vuota\n",
        "    w.writerow([])\n",
        "    # Global metrics\n",
        "    w.writerow([\"Global metrics (solo immagini con predizione)\"])\n",
        "    header = [\"tumori_trovati\",\"tumori_non_trovati\"] + list(global_means.index)\n",
        "    w.writerow(header)\n",
        "    vals   = [n_found, n_not_found] + [f\"{global_means[c]:.4f}\" for c in global_means.index]\n",
        "    w.writerow(vals)\n",
        "\n",
        "print(\"‚úÖ Tutto fatto! CSV finale: /content/Progetti_IA/SegmentazioneNoduliCerebrali/report/metrics_per_image.csv\")\n"
      ],
      "metadata": {
        "id": "9wPfwzEAqtT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SCRIPT PER LETTURA REPORT CSV E GENERAZIONE REPORT METRICHE AGGREGATE CSV ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "IN_CSV  = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/report/metrics_per_image.csv\"\n",
        "OUT_CSV = \"/content/Progetti_IA/SegmentazioneNoduliCerebrali/report/aggregate_metrics_per_class.csv\"\n",
        "\n",
        "# 1) Carica e filtra solo il tuo test set\n",
        "df = pd.read_csv(IN_CSV)\n",
        "df = df[df[\"image\"].astype(str).str.startswith(\"brisc2025\")].copy()\n",
        "\n",
        "# 2) Normalizza 'match' a int\n",
        "df[\"match\"] = pd.to_numeric(df[\"match\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# 3) Converti le metriche in float\n",
        "metric_cols = [\"iou\",\"dice\",\"precision\",\"recall\",\"specificity\",\"balanced_acc\",\"hausdorff_px\"]\n",
        "for col in metric_cols:\n",
        "    df[col] = (\n",
        "        df[col]\n",
        "        .astype(str)\n",
        "        .str.replace(\",\", \".\", regex=False)\n",
        "        .pipe(pd.to_numeric, errors=\"coerce\")\n",
        "        .fillna(0.0)\n",
        "    )\n",
        "\n",
        "# 4) Tieni solo le GT valide\n",
        "valid_gt = [\"Meningioma\", \"Glioma\", \"Pituitario\"]\n",
        "df = df[df[\"gt_class\"].isin(valid_gt)].copy()\n",
        "\n",
        "# --- DEBUG ---\n",
        "print(\"Righe dopo filtro:\", len(df))\n",
        "print(df[[\"image\",\"gt_class\",\"pred_class\",\"match\"]].head())\n",
        "\n",
        "# 5) Aggregazione\n",
        "rows = []\n",
        "for gt, grp in df.groupby(\"gt_class\"):\n",
        "    # conta predizioni corrette\n",
        "    correct      = int((grp[\"match\"] == 1).sum())\n",
        "    # conta predizioni sbagliate: classi NON NaN e match==0\n",
        "    wrong        = int(((grp[\"match\"] == 0) & (~grp[\"pred_class\"].isna())).sum())\n",
        "    # conta non rilevati (pred_class NaN)\n",
        "    not_detected = int(grp[\"pred_class\"].isna().sum())\n",
        "\n",
        "    # metrica media solo su correct==1\n",
        "    corr_grp = grp[grp[\"match\"] == 1]\n",
        "    if len(corr_grp):\n",
        "        agg = {c: corr_grp[c].mean() for c in metric_cols}\n",
        "    else:\n",
        "        agg = {c: 0.0 for c in metric_cols}\n",
        "\n",
        "    rows.append({\n",
        "        \"gt_class\":      gt,\n",
        "        \"correct_preds\": correct,\n",
        "        \"wrong_preds\":   wrong,\n",
        "        \"not_detected\":  not_detected,\n",
        "        **agg\n",
        "    })\n",
        "\n",
        "out_df = pd.DataFrame(rows, columns=[\n",
        "    \"gt_class\",\"correct_preds\",\"wrong_preds\",\"not_detected\", *metric_cols\n",
        "])\n",
        "\n",
        "# 6) Salva e stampa\n",
        "out_df.to_csv(OUT_CSV, index=False, float_format=\"%.4f\")\n",
        "print(f\"\\n‚úÖ Report aggregato per classe salvato in: {OUT_CSV}\\n\")\n",
        "print(out_df.to_string(index=False, float_format=\"%.4f\"))\n"
      ],
      "metadata": {
        "id": "Uqn28Nan_yMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}